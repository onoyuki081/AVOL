{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AVOL-Net-Model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYvxeV5dR1S1",
        "outputId": "4da3b2f3-b8aa-4664-b1cb-a2fbeec968f0"
      },
      "source": [
        "pip install pydub"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXyMIY_pR42w"
      },
      "source": [
        "import cv2\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "from tensorflow.keras import layers, models, Sequential\n",
        "import zipfile\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "import pydub\n",
        "from pydub import AudioSegment\n",
        "import scipy\n",
        "from scipy import signal\n",
        "from scipy.io import wavfile\n",
        "import random"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmKROvbUAPvM"
      },
      "source": [
        "def open_zip(zip_file):\n",
        "  try:\n",
        "    with zipfile.ZipFile(zip_file) as z:\n",
        "        z.extractall()\n",
        "        print(\"Extracted all\")\n",
        "  except:\n",
        "    print(\"Invalid file\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWCtV6n8_1KS"
      },
      "source": [
        "For creating the dummy data, we use the environment sound dataset (ESC-50.zip) from Harvard University.\n",
        "\n",
        "https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/YDEPUT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUip_F5MSDiA",
        "outputId": "8bb575a9-7a3b-4baa-fad4-03d772fe0948"
      },
      "source": [
        "# dataset.zip should contain the numpy arrays of audio and image\n",
        "for zf in [\"dataset.zip\", \"env_sound.zip\"]:\n",
        "  open(zf)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted all\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5ddxCS0SfM2"
      },
      "source": [
        "# load numpy arrays from each file\n",
        "audio = np.load('/content/content/dataset/audio/audio.npy')\n",
        "audio = np.multiply(audio, 0.01)\n",
        "image = np.load('/content/content/dataset/image/image.npy')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ftcVxpISrhJ"
      },
      "source": [
        "# store the dot product of audio and image\n",
        "audio_and_image = []"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1Ey0hE2SjJL"
      },
      "source": [
        "# get the dot product of image and audio.\n",
        "size = audio.shape[0]\n",
        "for i in list(range(size)):\n",
        "  im = image[i].transpose()\n",
        "  au = audio[i].reshape(30)                                                 \n",
        "  audio_and_image.append(np.dot(im, au))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJzH9O4LBFZN"
      },
      "source": [
        "For dummy audio and user input."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRqI9TDTSu46"
      },
      "source": [
        "def log_spectogram(wav_path):\n",
        "  sample_rate, samples = wavfile.read(wav_path)\n",
        "  f, t, Sxx = signal.spectrogram(samples, sample_rate)\n",
        "  Sxx = np.add(Sxx, 1)\n",
        "  Sxx = np.log10(Sxx)\n",
        "  return Sxx"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JS3t8NJ3Sw6M"
      },
      "source": [
        "def audio_conv(audio_log):\n",
        "  audio_log = np.resize(audio_log, (127, 196))\n",
        "  audio_log = np.reshape(audio_log, (1,) + audio_log.shape + (1,))\n",
        "  audio_log = layers.Conv2D(32, 5, activation='relu', input_shape=audio_log.shape[1:])(audio_log)\n",
        "  audio_log = layers.MaxPool2D()(audio_log)\n",
        "  audio_log = layers.Conv2D(32, 5, activation='relu', input_shape=audio_log.shape[1:])(audio_log)\n",
        "  audio_log = layers.MaxPool2D()(audio_log)\n",
        "  audio_log = layers.Flatten()(audio_log)\n",
        "  audio_log = layers.Dense(30, activation='relu')(audio_log)\n",
        "  return audio_log"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXclOmjiYTGN"
      },
      "source": [
        "# convert mp4 file to numpy array\n",
        "def video_processing(mp4_file):\n",
        "  frames = []\n",
        "  cap = cv2.VideoCapture(mp4_file)\n",
        "  ret = True\n",
        "  while ret:\n",
        "    ret, img = cap.read()\n",
        "    if ret:\n",
        "      frames.append(img)\n",
        "  video = np.stack(frames, axis=0)\n",
        "  video = video.astype('float32')\n",
        "  return video"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsoJkIOIYUAf"
      },
      "source": [
        "# convert nparray to (128, 256, 256) array using conv architecture\n",
        "def image_conv(video):\n",
        "  rgb_weights = [0.2989, 0.5870, 0.1140]\n",
        "  # convert image into gray scale.\n",
        "  video = np.dot(video[...,:3], rgb_weights)\n",
        "  video = np.resize(video, (30, 720, 1280, 1))\n",
        "  #video = layers.Conv2D(32, 5, activation='relu', input_shape=video.shape[1:])(video)\n",
        "  video = layers.MaxPool2D()(video)\n",
        "  #video = layers.Conv2D(32, 5, activation='relu', input_shape=video.shape[1:])(video)\n",
        "  video = layers.MaxPool2D()(video)\n",
        "  video = layers.MaxPool2D()(video)\n",
        "  video = np.resize(video, (30, 90, 160))\n",
        "  return video"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LW76F6f8SxkK"
      },
      "source": [
        "dummy_audio = []"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_EeMizmSzbJ"
      },
      "source": [
        "# convert dummy audio (= env sound) to log_spectogram \n",
        "# and apply CNN to compress the information.\n",
        "def process_dummy(path):\n",
        "  for f in os.listdir(path):\n",
        "    p = path + f\n",
        "    try:\n",
        "      spectogram = log_spectogram(p)\n",
        "      dummy_audio.append(audio_conv(spectogram))\n",
        "    except:\n",
        "      print(\"failed: \" + f)\n",
        "  dummy_audio = np.multiply(np.array(dummy_audio), 0.01)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lXjXlZKS1XL"
      },
      "source": [
        "process_dummy('/content/env_sound/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkJchacTS6Qq"
      },
      "source": [
        "# assign shuffled env_sound to each image.\n",
        "for i in list(range(size)):\n",
        "  im = image[i].transpose()\n",
        "  s = dummy_audio.shape[0]\n",
        "  r = random.randint(0, s-1)\n",
        "  au = dummy_audio[r].reshape(30)\n",
        "  audio_and_image.append(np.dot(im, au))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aa-dZdouS7Gz"
      },
      "source": [
        "audio_and_image = np.array(audio_and_image)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPEXgxb1TFMS"
      },
      "source": [
        "# making labels, 1 for true, 0 for false.\n",
        "labels = []\n",
        "labels.append(np.ones((size)))\n",
        "labels.append(np.zeros((size)))\n",
        "labels = np.array(labels)\n",
        "labels = labels.reshape(size*2, 1)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMuQqGDWS904"
      },
      "source": [
        "# split the data into train and test\n",
        "(trainX, testX, trainY, testY) = train_test_split(audio_and_image, labels, test_size=0.1, random_state=32)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxqgRQsVTGbT"
      },
      "source": [
        "# construct the model\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(160, 90, 1)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m339kwp_TIuy"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnIvdKNCTKls"
      },
      "source": [
        "from keras import backend as K\n",
        "K.set_value(model.optimizer.learning_rate, 0.001)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjQY3jmpTNGp"
      },
      "source": [
        "history = model.fit(trainX, trainY, epochs=100, \n",
        "                    validation_data=(testX, testY))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2yzWE3SMn8D"
      },
      "source": [
        "from google.colab import files\n",
        "def process_input(a_path, i_path):\n",
        "  input = []\n",
        "  v_numpy = image_conv(video_processing(i_path))\n",
        "  a_numpy = audio_conv(log_spectogram(a_path))\n",
        "  input.append(np.dot(im, au))\n",
        "  input = np.array(input)\n",
        "  predict = model.predict(input)\n",
        "  if predict > 0.5:\n",
        "    print(\"image and audio matches!\")\n",
        "  else:\n",
        "    print(\"image and audio doesn't match!\")"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBD7-t3sgU4N"
      },
      "source": [
        "process_input('/content/audio0 81sec.wav', '/content/video29 31sec.mp4')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}