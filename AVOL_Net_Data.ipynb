{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AVOL-Net-Data.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydMyg9auJuTo",
        "outputId": "9924e55a-a0c2-4651-c709-1779734640f6"
      },
      "source": [
        "# install necessary packages\n",
        "!pip install opencv-python\n",
        "!pip install pytube\n",
        "!pip install pydub"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python) (1.19.5)\n",
            "Collecting pytube\n",
            "  Downloading pytube-11.0.1-py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 4.0 MB/s \n",
            "\u001b[?25hInstalling collected packages: pytube\n",
            "Successfully installed pytube-11.0.1\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGINRRKLUMnF",
        "outputId": "24e32f31-450b-4989-c43d-67b3a6088d58"
      },
      "source": [
        "# upgrade pytube to obtain the data from YouTube\n",
        "!pip install --upgrade pytube"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytube in /usr/local/lib/python3.7/dist-packages (11.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnaTj5S_De1s"
      },
      "source": [
        "import cv2\n",
        "from pytube import YouTube\n",
        "import os\n",
        "import moviepy\n",
        "from moviepy.video.io.ffmpeg_tools import ffmpeg_extract_subclip\n",
        "from moviepy.video.io.VideoFileClip import VideoFileClip\n",
        "from moviepy.audio.io.AudioFileClip import AudioFileClip\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tempfile\n",
        "from tempfile import TemporaryFile\n",
        "import pydub\n",
        "from pydub import AudioSegment\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, Sequential\n",
        "import scipy\n",
        "from scipy import signal\n",
        "from scipy.io import wavfile\n",
        "from keras.layers import Conv1D, MaxPooling1D"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kk-wJmwZ4olE"
      },
      "source": [
        "We will use this dataset (test one) to collect the random videos from YouTube. \n",
        "\n",
        "https://looking-to-listen.github.io/avspeech/download.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjWx4Y7-E5A5"
      },
      "source": [
        "# put the avspeech_test.csv file to Files\n",
        "dataset = pd.read_csv('/content/avspeech_test.csv')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROMB6ZPWFBDz"
      },
      "source": [
        "# change the name of the columns for convenience\n",
        "dataset = dataset.rename(columns={\"u5MPyrRJPmc\": \"Youtube ID\", \"108.240000\": \"start segment\",\n",
        "                                  \"111.240000\": \"end segment\", \"0.849219\": \"X coordinate\",\n",
        "                                  \"0.305556\": \"Y coordinate\",})"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xC4uuWGJFyGy"
      },
      "source": [
        "# split the data by 1000\n",
        "newdata = dataset[:1000]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdCwA9t1Gk6b",
        "outputId": "553de70a-4b1e-4615-8aad-79b0d374ee1c"
      },
      "source": [
        "# create directory to save the video data temporarily and split the video data\n",
        "# into sound and video without sound \n",
        "directory = \"dataset\"\n",
        "parent_dir = \"/content/\"\n",
        "path = os.path.join(parent_dir, directory) \n",
        "try:\n",
        "  os.mkdir(path)\n",
        "  print(\"Directory '% s' created\" % directory) \n",
        "except:\n",
        "  print(\"Directory '% s' exists\" % directory)\n",
        "parent_dir = \"/content/dataset/\"\n",
        "# create subdirectories inside the \"/content/dataset/\"\n",
        "image_path = os.path.join(parent_dir, \"image\")\n",
        "audio_path = os.path.join(parent_dir, \"audio\")\n",
        "try:\n",
        "  os.mkdir(image_path)\n",
        "  os.mkdir(audio_path)\n",
        "except:\n",
        "  print(\"at least one of train and test directories already existed\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory 'dataset' exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qhW624FN_Nw"
      },
      "source": [
        "# for store numpy arrays of image and audio\n",
        "image_data = []\n",
        "audio_data = []"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gd3YA_4w7bWQ"
      },
      "source": [
        "# for clean up the directory specified by the path\n",
        "def cleanup(path):\n",
        "  for f in os.listdir(path):\n",
        "    try:\n",
        "      os.remove(os.path.join(path, f))\n",
        "    except:\n",
        "      print(f + \" : unable to remove\")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7rYo-dwPf9l"
      },
      "source": [
        "# convert wav file into log_spectogram\n",
        "def log_spectogram(wav_path):\n",
        "  sf, audio = wavfile.read(wav_path)\n",
        "  sig = np.mean(audio, axis = 1)\n",
        "  f, t, Sxx = signal.spectrogram(sig, sf)\n",
        "  Sxx = np.add(Sxx, 1)\n",
        "  Sxx = np.log10(Sxx)\n",
        "  return Sxx"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1Hgkwi_aCsf"
      },
      "source": [
        "# convert log_spectogram (2D array, which represents time and frequency), \n",
        "# into 1D array which size is (1, 30)\n",
        "def audio_conv(audio_log):\n",
        "  audio_log = np.reshape(audio_log, (1, 129, 196))\n",
        "  audio = Conv1D(filters = 1, kernel_size = 30, padding = 'same',\n",
        "                activation = 'relu')(audio_log)\n",
        "  audio = np.resize(audio_log, (1, 120, 1))\n",
        "  audio = MaxPooling1D(pool_size=4, padding='same')(audio)    \n",
        "  audio = Conv1D(filters = 1, kernel_size = 3, padding = 'same',\n",
        "                activation = 'relu')(audio)\n",
        "  audio = np.resize(audio_log, (1, 30))\n",
        "  return audio"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDBrFvtNQTQ8"
      },
      "source": [
        "# convert mp4 file to numpy array\n",
        "# the size of the numpy array for each image is \n",
        "# (time(30), height(720), width(1280), channels(3))\n",
        "def video_processing(mp4_file):\n",
        "  frames = []\n",
        "  cap = cv2.VideoCapture(mp4_file)\n",
        "  ret = True\n",
        "  while ret:\n",
        "    ret, img = cap.read()\n",
        "    if ret:\n",
        "      frames.append(img)\n",
        "  video = np.stack(frames, axis=0)\n",
        "  video = video.astype('float32')\n",
        "  return video"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBG6bGfsRGZq"
      },
      "source": [
        "# convert nparray to (30, 90, 160) array using conv architecture\n",
        "def image_conv(video):\n",
        "  rgb_weights = [0.2989, 0.5870, 0.1140]\n",
        "  # convert image into gray scale for reducing a dimension.\n",
        "  video = np.dot(video[...,:3], rgb_weights)\n",
        "  video = np.resize(video, (30, 720, 1280, 1))\n",
        "  # compress the image by using maxpooling.\n",
        "  video = layers.MaxPool2D()(video)\n",
        "  video = layers.MaxPool2D()(video)\n",
        "  video = layers.MaxPool2D()(video)\n",
        "  video = np.resize(video, (30, 90, 160))\n",
        "  return video"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzqOE0LeKIA-",
        "outputId": "da2514e5-9614-4c8b-dd37-c8ffdfb238a4"
      },
      "source": [
        "counter = 0\n",
        "for row in newdata.iterrows():\n",
        "  ID = row[1][0]\n",
        "  start = int(row[1][1]) + 1\n",
        "  end = int(row[1][2])\n",
        "  path = \"https://www.youtube.com/watch?v=\" + ID\n",
        "  try:\n",
        "    yt = YouTube(path)\n",
        "    # yt.streams do not work (11.23.2021)\n",
        "    audio = yt.streams.filter(only_audio=True)[0].download('/content/dataset/audio/', filename=ID)\n",
        "    image = yt.streams.filter(only_video=True)[0].download('/content/dataset/image/', filename=ID)\n",
        "    audio_inputpath = '/content/dataset/audio/' + ID\n",
        "    image_inputpath = '/content/dataset/image/' + ID\n",
        "    audio_outputpath = '/content/dataset/audio/' + ID + ' ' + str(start) + 'sec' + '.wav'\n",
        "    # for each audio and video, we will get one second of audio without sound \n",
        "    # and one second of sound.\n",
        "    # after we extract the audio and video from each clip, append it into \n",
        "    # image_data and audio_data with numpy format.\n",
        "    with AudioFileClip(audio_inputpath) as audio:\n",
        "      clip = audio.subclip(start, start + 1)\n",
        "      clip.write_audiofile(audio_outputpath)\n",
        "      spectogram = log_spectogram(audio_outputpath)\n",
        "      audio_data.append(audio_conv(spectogram))\n",
        "    image_outputpath = '/content/dataset/image/' + ID + ' ' + str(start) + 'sec' + '.mp4'\n",
        "    with VideoFileClip(image_inputpath) as video:\n",
        "      clip = video.subclip(start, start + 1)\n",
        "      clip.write_videofile(image_outputpath, audio_codec='aac')\n",
        "      processed = video_processing(image_outputpath)\n",
        "      image_data.append(image_conv(processed))  \n",
        "    cleanup('/content/dataset/audio')\n",
        "    cleanup('/content/dataset/image')\n",
        "  except:\n",
        "    message = ID + \" : video not found.\"\n",
        "    print(message)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[MoviePy] Writing audio in /content/dataset/audio/H1ulMfj5wRY 113sec.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 23/23 [00:00<00:00, 177.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[MoviePy] Done.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[MoviePy] >>>> Building video /content/dataset/image/H1ulMfj5wRY 113sec.mp4\n",
            "[MoviePy] Writing video /content/dataset/image/H1ulMfj5wRY 113sec.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 98%|█████████▊| 50/51 [00:01<00:00, 43.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "H1ulMfj5wRY : video not found.\n",
            "-wuxbgMRIWs : video not found.\n",
            "[MoviePy] Writing audio in /content/dataset/audio/GNRPRH-E-sI 31sec.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 23/23 [00:00<00:00, 180.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[MoviePy] Done.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[MoviePy] >>>> Building video /content/dataset/image/GNRPRH-E-sI 31sec.mp4\n",
            "[MoviePy] Writing video /content/dataset/image/GNRPRH-E-sI 31sec.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [00:00<00:00, 57.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[MoviePy] Done.\n",
            "[MoviePy] >>>> Video ready: /content/dataset/image/GNRPRH-E-sI 31sec.mp4 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AfWpIB38ZAW"
      },
      "source": [
        "# save numpy arrays as npy format\n",
        "np.save('/content/dataset/audio/audio.npy', np.array(audio_data))\n",
        "np.save('/content/dataset/image/image.npy', np.array(image_data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZ6joQVWNzMu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f4e6c2d-8c25-4ad2-8473-a29a98ea6b3d"
      },
      "source": [
        "# convert dataset folder into zip file\n",
        "!zip -r /content/dataset.zip /content/dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/dataset/ (stored 0%)\n",
            "  adding: content/dataset/audio/ (stored 0%)\n",
            "  adding: content/dataset/audio/audio.npy (deflated 47%)\n",
            "  adding: content/dataset/image/ (stored 0%)\n",
            "  adding: content/dataset/image/image.npy (deflated 47%)\n"
          ]
        }
      ]
    }
  ]
}